{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import tensorflow.keras.datasets as datasets\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "(train, test), metadata = tfds.load(\n",
    "    \"mnist\",\n",
    "    split = [\"train\", \"test\"],\n",
    "    shuffle_files = True,\n",
    "    as_supervised = True,\n",
    "    with_info = True,\n",
    ")\n",
    "\n",
    "def normalize_data(image, label):\n",
    "    return tf.cast(image, tf.float32)/255.0, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train = train.map(normalize_data, num_parallel_calls =AUTOTUNE)\n",
    "train = train.cache()\n",
    "train = train.shuffle(metadata.splits[\"train\"].num_examples)\n",
    "train = train.batch(BATCH_SIZE)\n",
    "train = train.prefetch(AUTOTUNE)\n",
    "\n",
    "test = test.map(normalize_data, num_parallel_calls = AUTOTUNE)\n",
    "test = test.cache()\n",
    "# test = test.shuffle(metadata.splits[\"test\"].num_examples)\n",
    "test = test.batch(BATCH_SIZE)\n",
    "test = test.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size = 3):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(out_channels, kernel_size, padding = 'same')\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        # self.relu = keras.activations.relu\n",
    "        self.relu = layers.ReLU()\n",
    "        \n",
    "    def call(self, input_tensor, training = False):\n",
    "        x = self.conv1(input_tensor)\n",
    "        x = self.bn(x, training = training)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Model\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " cnn_block_1 (CNNBlock)      (None, 28, 28, 32)        448       \n",
      "                                                                 \n",
      " cnn_block_2 (CNNBlock)      (None, 28, 28, 64)        18752     \n",
      "                                                                 \n",
      " cnn_block_3 (CNNBlock)      (None, 28, 28, 128)       74368     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111,370\n",
      "Trainable params: 0\n",
      "Non-trainable params: 111,370\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "New Model\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " cnn_block_1 (CNNBlock)      (None, 28, 28, 32)        448       \n",
      "                                                                 \n",
      " cnn_block_2 (CNNBlock)      (None, 28, 28, 64)        18752     \n",
      "                                                                 \n",
      " cnn_block_3 (CNNBlock)      (None, 28, 28, 128)       74368     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111,370\n",
      "Trainable params: 1,290\n",
      "Non-trainable params: 110,080\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "old_model = keras.models.load_model(\"pretrained/BasicCNN/\", custom_objects = {'CNNBlock': CNNBlock})\n",
    "old_model.trainable = False\n",
    "print(\"Old Model\")\n",
    "print(old_model.summary())\n",
    "base_input = old_model.input\n",
    "base_output = old_model.layers[-2].output\n",
    "classification = layers.Dense(10)(base_output)\n",
    "model = Model(inputs = [base_input, ], outputs = [classification, ])\n",
    "print()\n",
    "print(\"New Model\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n",
    "    metrics = ['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 - 12s - loss: 0.4108 - accuracy: 0.9193 - 12s/epoch - 13ms/step\n",
      "Epoch 2/5\n",
      "938/938 - 7s - loss: 0.1149 - accuracy: 0.9717 - 7s/epoch - 8ms/step\n",
      "Epoch 3/5\n",
      "938/938 - 7s - loss: 0.0942 - accuracy: 0.9736 - 7s/epoch - 8ms/step\n",
      "Epoch 4/5\n",
      "938/938 - 7s - loss: 0.0877 - accuracy: 0.9745 - 7s/epoch - 8ms/step\n",
      "Epoch 5/5\n",
      "938/938 - 7s - loss: 0.0817 - accuracy: 0.9756 - 7s/epoch - 7ms/step\n",
      "\n",
      "157/157 - 1s - loss: 0.0742 - accuracy: 0.9774 - 1s/epoch - 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07421784102916718, 0.977400004863739]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, verbose = 2, epochs = 5)\n",
    "print()\n",
    "model.evaluate(test, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "(text_train, text_test), metadata = tfds.load(\n",
    "    \"imdb_reviews\",\n",
    "    split = [\"train\", \"test\"],\n",
    "    shuffle_files = True,\n",
    "    as_supervised = True,\n",
    "    with_info = True,\n",
    ")\n",
    "\n",
    "tokenizer = tfds.deprecated.text.Tokenizer()\n",
    "def build_vocabulary(train):\n",
    "    vocab = set()\n",
    "    for text, _ in train:\n",
    "        vocab.update(tokenizer.tokenize(text.numpy().lower()))\n",
    "    return vocab\n",
    "\n",
    "vocab = build_vocabulary(text_train)\n",
    "encoder = tfds.deprecated.text.TokenTextEncoder(\n",
    "    vocab, oov_token = \"<UNK>\", lowercase = True, tokenizer = tokenizer\n",
    ")\n",
    "\n",
    "def encode_data(text, label):\n",
    "    return encoder.encode(text.numpy()), label\n",
    "\n",
    "def encode_map(text, label):\n",
    "    encoded_text, label = tf.py_function(\n",
    "        encode_data, inp = [text, label], Tout = [tf.int64, tf.int64]\n",
    "    )\n",
    "    encoded_text.set_shape([None])\n",
    "    label.set_shape([]) \n",
    "    return encoded_text, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "text_train = text_train.map(encode_map, num_parallel_calls = AUTOTUNE).cache()\n",
    "text_train = text_train.shuffle(metadata.splits[\"train\"].num_examples)\n",
    "text_train = text_train.padded_batch(32, padded_shapes=([None], ()))\n",
    "text_train = text_train.prefetch(AUTOTUNE)\n",
    "\n",
    "text_test = text_test.map(encode_map, num_parallel_calls = AUTOTUNE).cache()\n",
    "text_test = text_test.padded_batch(32, padded_shapes=([None], ()))\n",
    "text_test = text_test.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_text = Sequential([\n",
    "    layers.Masking(mask_value = 0),\n",
    "    layers.Embedding(input_dim = len(vocab)+2, output_dim=32),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 - 31s - loss: 0.5344 - accuracy: 0.6736 - 31s/epoch - 40ms/step\n",
      "Epoch 2/5\n",
      "782/782 - 5s - loss: 0.2628 - accuracy: 0.8931 - 5s/epoch - 7ms/step\n",
      "Epoch 3/5\n",
      "782/782 - 6s - loss: 0.1906 - accuracy: 0.9270 - 6s/epoch - 7ms/step\n",
      "Epoch 4/5\n",
      "782/782 - 5s - loss: 0.1400 - accuracy: 0.9495 - 5s/epoch - 7ms/step\n",
      "Epoch 5/5\n",
      "782/782 - 5s - loss: 0.1074 - accuracy: 0.9642 - 5s/epoch - 7ms/step\n",
      "\n",
      "782/782 - 32s - loss: 0.3148 - accuracy: 0.8825 - 32s/epoch - 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3148319125175476, 0.8825200200080872]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_text.compile(\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n",
    "    metrics = ['accuracy'],\n",
    ")\n",
    "\n",
    "model_text.fit(text_train, verbose = 2, epochs = 5)\n",
    "print()\n",
    "model_text.evaluate(text_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking (Masking)           (None, None)              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 32)          2396640   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 32)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,398,817\n",
      "Trainable params: 2,398,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model_text.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
