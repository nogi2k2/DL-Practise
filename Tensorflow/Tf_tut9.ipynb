{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, test), metadata = tfds.load(\n",
    "    \"mnist\",\n",
    "    split = [\"train\", \"test\"],\n",
    "    shuffle_files = True,\n",
    "    as_supervised = True,\n",
    "    with_info = True,\n",
    ")\n",
    "\n",
    "def normalize(image, label):\n",
    "    return tf.cast(image, tf.float32)/255.0, label\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train = train.map(normalize, num_parallel_calls = AUTOTUNE).cache()\n",
    "train = train.shuffle(metadata.splits[\"train\"].num_examples)\n",
    "train = train.batch(BATCH_SIZE)\n",
    "train = train.prefetch(AUTOTUNE)\n",
    "\n",
    "test = test.map(normalize, num_parallel_calls = AUTOTUNE).cache()\n",
    "test = test.batch(BATCH_SIZE)\n",
    "test = test.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 64)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,010\n",
      "Trainable params: 23,818\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inp = keras.Input(shape = (28,28,1))\n",
    "conv1 = layers.Conv2D(32, 3, padding = 'same')(inp)\n",
    "bn1 = layers.BatchNormalization()(conv1)\n",
    "a1 = layers.ReLU()(bn1)\n",
    "pool1 = layers.MaxPool2D()(a1)\n",
    "conv2 = layers.Conv2D(64, 3, padding = 'same')(pool1)\n",
    "bn2 = layers.BatchNormalization()(conv2)\n",
    "a2 = layers.ReLU()(bn2)\n",
    "pool2 = layers.MaxPool2D()(a2)\n",
    "gap = layers.GlobalAveragePooling2D()(pool2)\n",
    "dense1 = layers.Dense(64, activation = 'relu')(gap)\n",
    "classification = layers.Dense(10)(dense1)\n",
    "\n",
    "model = Model(inputs = [inp, ], outputs = [classification, ])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "optimizer = keras.optimizers.Adam(learning_rate = 0.001)\n",
    "acc_metric = keras.metrics.SparseCategoricalAccuracy(name = \"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  10%|█         | 1/10 [01:09<10:28, 69.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.1184205412864685 | Accuracy: 79.883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  20%|██        | 2/10 [02:15<08:58, 67.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss: 0.11788301169872284 | Accuracy: 93.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  30%|███       | 3/10 [03:21<07:48, 66.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Loss: 0.10485751181840897 | Accuracy: 95.370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  40%|████      | 4/10 [04:18<06:16, 62.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Loss: 0.036650434136390686 | Accuracy: 96.123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  50%|█████     | 5/10 [05:14<05:01, 60.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Loss: 0.21699313819408417 | Accuracy: 96.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  60%|██████    | 6/10 [06:12<03:59, 59.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Loss: 0.18185117840766907 | Accuracy: 96.860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  70%|███████   | 7/10 [07:02<02:49, 56.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Loss: 0.04065380617976189 | Accuracy: 97.117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  80%|████████  | 8/10 [07:52<01:48, 54.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Loss: 0.06066937744617462 | Accuracy: 97.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  90%|█████████ | 9/10 [08:46<00:54, 54.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Loss: 0.012823467142879963 | Accuracy: 97.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 10/10 [09:41<00:00, 58.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Loss: 0.005378000438213348 | Accuracy: 97.690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Train Step\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc = \"Training Epochs\"):\n",
    "    for batch_idx, (x, y) in enumerate(train):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x, training = True)\n",
    "            loss = loss_fn(y, y_pred)\n",
    "        training_vars = model.trainable_weights\n",
    "        gradients = tape.gradient(loss, training_vars)\n",
    "        optimizer.apply_gradients(zip(gradients, training_vars))\n",
    "        acc_metric.update_state(y, y_pred)\n",
    "\n",
    "    print(f\"Epoch: {epoch} | Loss: {loss} | Accuracy: {acc_metric.result().numpy()*100:.3f}\")\n",
    "    acc_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1587207317352295 | Accuracy: 89.200\n"
     ]
    }
   ],
   "source": [
    "#Test Step\n",
    "for batch_idx, (x, y) in enumerate(test):\n",
    "    y_pred = model(x, training = False)    \n",
    "    loss = loss_fn(y, y_pred)\n",
    "    acc_metric.update_state(y, y_pred)\n",
    "print(f\"Loss: {loss} | Accuracy: {acc_metric.result().numpy()*100:.3f}\")\n",
    "acc_metric.reset_states()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
